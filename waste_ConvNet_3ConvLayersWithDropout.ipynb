{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making directory for tensorboard\n",
    "NAME = \"waste_ConvNet_3ConvLayersWithDropout\"\n",
    "\n",
    "tboard_log_dir = os.path.join(\"logs\",NAME)\n",
    "tensorboard = TensorBoard(log_dir = tboard_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL CONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Convolution Layer\n",
    "model.add(Conv2D(32,(3,3), input_shape = (64,64,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Convolution Layer\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Convolution Layer\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Layer to accept Flattened array\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Dense Layer to predict Recyclable or Organic\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Applying Image Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22564 images belonging to 2 classes.\n",
      "Found 2513 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating test and train sets\n",
    "training_set = train_datagen.flow_from_directory('DATASET/TRAIN',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('DATASET/TEST',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-1f9197a6d53b>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 705 steps, validate for 79 steps\n",
      "Epoch 1/15\n",
      "705/705 [==============================] - 152s 215ms/step - loss: 0.4633 - accuracy: 0.7892 - val_loss: 0.3664 - val_accuracy: 0.8822\n",
      "Epoch 2/15\n",
      "705/705 [==============================] - 130s 184ms/step - loss: 0.4052 - accuracy: 0.8252 - val_loss: 0.3486 - val_accuracy: 0.8735\n",
      "Epoch 3/15\n",
      "705/705 [==============================] - 135s 191ms/step - loss: 0.3842 - accuracy: 0.8337 - val_loss: 0.3655 - val_accuracy: 0.8563\n",
      "Epoch 4/15\n",
      "705/705 [==============================] - 144s 205ms/step - loss: 0.3663 - accuracy: 0.8453 - val_loss: 0.3037 - val_accuracy: 0.8766\n",
      "Epoch 5/15\n",
      "705/705 [==============================] - 145s 205ms/step - loss: 0.3535 - accuracy: 0.8491 - val_loss: 0.2835 - val_accuracy: 0.8914\n",
      "Epoch 6/15\n",
      "705/705 [==============================] - 129s 184ms/step - loss: 0.3470 - accuracy: 0.8547 - val_loss: 0.2769 - val_accuracy: 0.8934\n",
      "Epoch 7/15\n",
      "705/705 [==============================] - 132s 187ms/step - loss: 0.3441 - accuracy: 0.8570 - val_loss: 0.2809 - val_accuracy: 0.8938\n",
      "Epoch 8/15\n",
      "705/705 [==============================] - 130s 185ms/step - loss: 0.3340 - accuracy: 0.8612 - val_loss: 0.2564 - val_accuracy: 0.8957\n",
      "Epoch 9/15\n",
      "705/705 [==============================] - 135s 192ms/step - loss: 0.3318 - accuracy: 0.8615 - val_loss: 0.2628 - val_accuracy: 0.9029\n",
      "Epoch 10/15\n",
      "705/705 [==============================] - 131s 185ms/step - loss: 0.3271 - accuracy: 0.8641 - val_loss: 0.3220 - val_accuracy: 0.8647\n",
      "Epoch 11/15\n",
      "705/705 [==============================] - 130s 185ms/step - loss: 0.3212 - accuracy: 0.8672 - val_loss: 0.2415 - val_accuracy: 0.9101\n",
      "Epoch 12/15\n",
      "705/705 [==============================] - 134s 190ms/step - loss: 0.3128 - accuracy: 0.8699 - val_loss: 0.2814 - val_accuracy: 0.8910\n",
      "Epoch 13/15\n",
      "705/705 [==============================] - 128s 182ms/step - loss: 0.3124 - accuracy: 0.8721 - val_loss: 0.2608 - val_accuracy: 0.9073\n",
      "Epoch 14/15\n",
      "705/705 [==============================] - 130s 185ms/step - loss: 0.3074 - accuracy: 0.8740 - val_loss: 0.2695 - val_accuracy: 0.8910\n",
      "Epoch 15/15\n",
      "705/705 [==============================] - 126s 179ms/step - loss: 0.3038 - accuracy: 0.8749 - val_loss: 0.2806 - val_accuracy: 0.9025\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# steps per epoch is 705 as result of training instance/batch size = 22564/32 ~ 706 same reasoning for validation_steps(2513/32)\n",
    "history = model.fit_generator(training_set,\n",
    "                    steps_per_epoch = 705 ,\n",
    "                    epochs = 15,\n",
    "                    validation_data = test_set,\n",
    "                    validation_steps = 79,\n",
    "                    callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: 3ConVLayerWithDropoutRegularization\\assets\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "model.save('3ConVLayerWithDropoutRegularization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('DATASET/TEST/Recyclable/R_10840.jpg',\n",
    "                            target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x2195D1EFCC0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Organic': 0, 'Recyclable': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'Recyclable'\n",
    "else:\n",
    "    prediction = 'Organic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recyclable'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
