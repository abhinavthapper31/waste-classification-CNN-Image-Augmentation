{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making directory for tensorboard\n",
    "NAME = \"waste_ConvNet_3ConvLayers\"\n",
    "\n",
    "tboard_log_dir = os.path.join(\"logs\",NAME)\n",
    "tensorboard = TensorBoard(log_dir = tboard_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Convolution Layer\n",
    "model.add(Conv2D(32,(3,3), input_shape = (64,64,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Convolution Layer\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Convolution Layer\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Layer to accept Flattened array\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Dense Layer to predict Recyclable or Organic\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Applying Image Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22564 images belonging to 2 classes.\n",
      "Found 2513 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating test and train sets\n",
    "training_set = train_datagen.flow_from_directory('DATASET/TRAIN',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('DATASET/TEST',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-1f9197a6d53b>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 705 steps, validate for 79 steps\n",
      "Epoch 1/15\n",
      "705/705 [==============================] - 139s 198ms/step - loss: 0.4381 - accuracy: 0.8054 - val_loss: 0.3221 - val_accuracy: 0.8778\n",
      "Epoch 2/15\n",
      "705/705 [==============================] - 142s 201ms/step - loss: 0.3850 - accuracy: 0.8345 - val_loss: 0.3281 - val_accuracy: 0.8679\n",
      "Epoch 3/15\n",
      "705/705 [==============================] - 143s 203ms/step - loss: 0.3673 - accuracy: 0.8421 - val_loss: 0.2891 - val_accuracy: 0.8846\n",
      "Epoch 4/15\n",
      "705/705 [==============================] - 140s 199ms/step - loss: 0.3448 - accuracy: 0.8555 - val_loss: 0.2820 - val_accuracy: 0.8838\n",
      "Epoch 5/15\n",
      "705/705 [==============================] - 144s 204ms/step - loss: 0.3397 - accuracy: 0.8573 - val_loss: 0.3156 - val_accuracy: 0.8814\n",
      "Epoch 6/15\n",
      "705/705 [==============================] - 144s 205ms/step - loss: 0.3272 - accuracy: 0.8634 - val_loss: 0.2708 - val_accuracy: 0.9025\n",
      "Epoch 7/15\n",
      "705/705 [==============================] - 146s 207ms/step - loss: 0.3180 - accuracy: 0.8701 - val_loss: 0.2516 - val_accuracy: 0.9053\n",
      "Epoch 8/15\n",
      "705/705 [==============================] - 154s 218ms/step - loss: 0.3051 - accuracy: 0.8748 - val_loss: 0.3682 - val_accuracy: 0.8456\n",
      "Epoch 9/15\n",
      "705/705 [==============================] - 134s 190ms/step - loss: 0.2988 - accuracy: 0.8747 - val_loss: 0.3532 - val_accuracy: 0.8444\n",
      "Epoch 10/15\n",
      "705/705 [==============================] - 135s 192ms/step - loss: 0.2936 - accuracy: 0.8792 - val_loss: 0.3048 - val_accuracy: 0.8699\n",
      "Epoch 11/15\n",
      "705/705 [==============================] - 141s 199ms/step - loss: 0.2844 - accuracy: 0.8830 - val_loss: 0.2616 - val_accuracy: 0.9013\n",
      "Epoch 12/15\n",
      "705/705 [==============================] - 161s 229ms/step - loss: 0.2755 - accuracy: 0.8883 - val_loss: 0.2725 - val_accuracy: 0.9001\n",
      "Epoch 13/15\n",
      "705/705 [==============================] - 137s 194ms/step - loss: 0.2700 - accuracy: 0.8897 - val_loss: 0.2745 - val_accuracy: 0.8985\n",
      "Epoch 14/15\n",
      "705/705 [==============================] - 138s 195ms/step - loss: 0.2632 - accuracy: 0.8934 - val_loss: 0.2622 - val_accuracy: 0.9013\n",
      "Epoch 15/15\n",
      "705/705 [==============================] - 131s 186ms/step - loss: 0.2593 - accuracy: 0.8951 - val_loss: 0.2967 - val_accuracy: 0.8862\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# steps per epoch is 705 as result of training instance/batch size = 22564/32 ~ 706 same reasoning for validation_steps(2513/32)\n",
    "history = model.fit_generator(training_set,\n",
    "                    steps_per_epoch = 705 ,\n",
    "                    epochs = 15,\n",
    "                    validation_data = test_set,\n",
    "                    validation_steps = 79,\n",
    "                    callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: 3ConvLayer\\assets\n"
     ]
    }
   ],
   "source": [
    "# Saving\n",
    "model.save('3ConvLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
