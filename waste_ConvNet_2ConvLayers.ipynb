{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making directory for tensorboard\n",
    "NAME = \"waste_ConvNet_2ConvLayers\"\n",
    "\n",
    "tboard_log_dir = os.path.join(\"logs\",NAME)\n",
    "tensorboard = TensorBoard(log_dir = tboard_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Convolution Layer\n",
    "model.add(Conv2D(32,(3,3), input_shape = (64,64,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Convolution Layer\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Layer to accept Flattened array\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Dense Layer to predict Recyclable or Organic\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparametes\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22564 images belonging to 2 classes.\n",
      "Found 2513 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training and tests sets\n",
    "training_set = train_datagen.flow_from_directory('DATASET/TRAIN',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('DATASET/TEST',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-1f9197a6d53b>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 705 steps, validate for 79 steps\n",
      "Epoch 1/15\n",
      "705/705 [==============================] - 136s 193ms/step - loss: 0.4386 - accuracy: 0.8045 - val_loss: 0.3767 - val_accuracy: 0.8408\n",
      "Epoch 2/15\n",
      "705/705 [==============================] - 143s 204ms/step - loss: 0.3970 - accuracy: 0.8261 - val_loss: 0.3168 - val_accuracy: 0.8663\n",
      "Epoch 3/15\n",
      "705/705 [==============================] - 151s 214ms/step - loss: 0.3691 - accuracy: 0.8385 - val_loss: 0.3336 - val_accuracy: 0.8647\n",
      "Epoch 4/15\n",
      "705/705 [==============================] - 148s 209ms/step - loss: 0.3536 - accuracy: 0.8497 - val_loss: 0.3719 - val_accuracy: 0.8548\n",
      "Epoch 5/15\n",
      "705/705 [==============================] - 144s 205ms/step - loss: 0.3442 - accuracy: 0.8543 - val_loss: 0.3005 - val_accuracy: 0.8878\n",
      "Epoch 6/15\n",
      "705/705 [==============================] - 143s 203ms/step - loss: 0.3272 - accuracy: 0.8622 - val_loss: 0.3293 - val_accuracy: 0.8798\n",
      "Epoch 7/15\n",
      "705/705 [==============================] - 143s 202ms/step - loss: 0.3183 - accuracy: 0.8669 - val_loss: 0.2909 - val_accuracy: 0.8838\n",
      "Epoch 8/15\n",
      "705/705 [==============================] - 135s 191ms/step - loss: 0.3080 - accuracy: 0.8708 - val_loss: 0.2948 - val_accuracy: 0.8922\n",
      "Epoch 9/15\n",
      "705/705 [==============================] - 137s 194ms/step - loss: 0.2962 - accuracy: 0.8773 - val_loss: 0.3174 - val_accuracy: 0.8850\n",
      "Epoch 10/15\n",
      "705/705 [==============================] - 142s 202ms/step - loss: 0.2879 - accuracy: 0.8801 - val_loss: 0.2976 - val_accuracy: 0.8830\n",
      "Epoch 11/15\n",
      "705/705 [==============================] - 146s 208ms/step - loss: 0.2789 - accuracy: 0.8824 - val_loss: 0.2845 - val_accuracy: 0.8922\n",
      "Epoch 12/15\n",
      "705/705 [==============================] - 134s 190ms/step - loss: 0.2682 - accuracy: 0.8914 - val_loss: 0.3253 - val_accuracy: 0.8723\n",
      "Epoch 13/15\n",
      "705/705 [==============================] - 133s 188ms/step - loss: 0.2611 - accuracy: 0.8933 - val_loss: 0.2917 - val_accuracy: 0.8918\n",
      "Epoch 14/15\n",
      "705/705 [==============================] - 134s 191ms/step - loss: 0.2522 - accuracy: 0.8966 - val_loss: 0.3153 - val_accuracy: 0.8798\n",
      "Epoch 15/15\n",
      "705/705 [==============================] - 132s 187ms/step - loss: 0.2470 - accuracy: 0.9005 - val_loss: 0.2928 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# steps per epoch is 705 as result of training instance/batch size = 22564/32 ~ 706 same reasoning for validation_steps(2513/32)\n",
    "history = model.fit_generator(training_set,\n",
    "                    steps_per_epoch = 705 ,\n",
    "                    epochs = 15,\n",
    "                    validation_data = test_set,\n",
    "                    validation_steps = 79,\n",
    "                    callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: 2ConvLayers\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('2ConvLayers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
